{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/anaconda3/envs/myenv/lib/python311.zip', '/opt/anaconda3/envs/myenv/lib/python3.11', '/opt/anaconda3/envs/myenv/lib/python3.11/lib-dynload', '', '/opt/anaconda3/envs/myenv/lib/python3.11/site-packages', '/Users/cmazzoleni/Documents/GitHub/Hierarchical-Localization/Hierarchical-Localization/Hierarchical-Localization', '/Users/cmazzoleni/Documents/GitHub/SemesterProjectETH']\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import os\n",
    "import sys\n",
    "# Define the path to the project root directory (one level above `src`)\n",
    "project_root_path = \"/Users/cmazzoleni/Documents/GitHub/SemesterProjectETH\"\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "sys.path.append(os.path.join(project_root_path))\n",
    "\n",
    "# Verify that src is in sys.path\n",
    "print(sys.path)\n",
    "import os\n",
    "import argparse\n",
    "from src.utils.dataset_utils import create_directory\n",
    "from src.visualizers.Open3dVisualizer import Open3DVisualizer\n",
    "from src.utils.json_utils import load_cuboid_data\n",
    "from src.utils.plotting_utils import load_mesh_data, load_pointcloud_data\n",
    "from src.scripts.preprocessing_data.data_to_6views_utils import process_file\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "visualizer = Open3DVisualizer()\n",
    "\n",
    "mesh_path = \"/Users/cmazzoleni/Documents/GitHub/SemesterProjectETH/data/raw/03001627/185bcb9bcec174c9492d9da2668ec34c/models/model_normalized.obj\"\n",
    "mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "visualizer.vis.add_geometry(mesh)\n",
    "\n",
    "front_view_direction = [0, 0, -1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Capture rgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front view screenshot saved as front_rgb_mesh_image.png\n"
     ]
    }
   ],
   "source": [
    "front_view_direction = [0, 0, -1]  # Front view direction (camera looking towards -z)\n",
    "\n",
    "# Save the front view RGB image\n",
    "front_rgb_mesh_filename = \"front_rgb_mesh_image.png\"\n",
    "visualizer.capture_front_picture(front_rgb_mesh_filename)\n",
    "\n",
    "rgb = np.array(Image.open(front_rgb_mesh_filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front view screenshot saved as front_depth_mesh_image.png\n",
      "min_depth:  0\n",
      "max_depth:  1096\n"
     ]
    }
   ],
   "source": [
    "# Save the front view depth image\n",
    "front_depth_mesh_filename = \"front_depth_mesh_image.png\"\n",
    "visualizer.capture_front_depth(front_depth_mesh_filename, distance=1.0, depth_scale=1000.0)\n",
    "\n",
    "# The front_depth_filename will store the normalized depth image\n",
    "#find min and max values\n",
    "depth_image = np.array(Image.open(front_depth_mesh_filename))\n",
    "min_depth = np.min(depth_image)\n",
    "max_depth = np.max(depth_image)\n",
    "print(\"min_depth: \", min_depth)\n",
    "print(\"max_depth: \", max_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypersim processing Tonemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_map(rgb):\n",
    "    gamma = 1.0 / 2.2  # standard gamma correction exponent\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    percentile = 90  # we want this percentile brightness value in the unmodified image...\n",
    "    brightness_nth_percentile_desired = 0.8  # ...to be this bright after scaling\n",
    "\n",
    "    # Generate a synthetic entity_id_map where all pixels are valid\n",
    "    entity_id_map = np.ones(rgb.shape[:2], dtype=np.int32)\n",
    "\n",
    "    valid_mask = entity_id_map != -1  # In this case, all pixels are valid\n",
    "    brightness = (\n",
    "        0.3 * rgb[:, :, 0] + 0.59 * rgb[:, :, 1] + 0.11 * rgb[:, :, 2]\n",
    "    )\n",
    "    brightness_valid = brightness[valid_mask]\n",
    "\n",
    "    eps = 0.0001\n",
    "    brightness_nth_percentile_current = np.percentile(brightness_valid, percentile)\n",
    "\n",
    "    if brightness_nth_percentile_current < eps:\n",
    "        scale = 0.0\n",
    "    else:\n",
    "        scale = (\n",
    "            np.power(brightness_nth_percentile_desired, inv_gamma)\n",
    "            / brightness_nth_percentile_current\n",
    "        )\n",
    "\n",
    "    # Apply tone mapping\n",
    "    rgb_color_tm = np.power(np.maximum(scale * rgb, 0), gamma)\n",
    "    rgb_color_tm = np.clip(rgb_color_tm, 0, 1)\n",
    "\n",
    "    return rgb_color_tm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply tone map to rgb image\n",
    "\n",
    "rgb_color_tm = tone_map(rgb)\n",
    "rgb_int = (rgb_color_tm * 255).astype(np.uint8)  # [H, W, RGB]\n",
    "cv2.imwrite(\"front_rgb_mesh_image_tonemapped.png\", cv2.cvtColor(rgb_int, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypersim processing dist to depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to https://github.com/apple/ml-hypersim/issues/9\n",
    "def dist_2_depth(width, height, flt_focal, distance):\n",
    "    img_plane_x = (\n",
    "        np.linspace((-0.5 * width) + 0.5, (0.5 * width) - 0.5, width)\n",
    "        .reshape(1, width)\n",
    "        .repeat(height, 0)\n",
    "        .astype(np.float32)[:, :, None]\n",
    "    )\n",
    "    img_plane_y = (\n",
    "        np.linspace((-0.5 * height) + 0.5, (0.5 * height) - 0.5, height)\n",
    "        .reshape(height, 1)\n",
    "        .repeat(width, 1)\n",
    "        .astype(np.float32)[:, :, None]\n",
    "    )\n",
    "    img_plane_z = np.full([height, width, 1], flt_focal, np.float32)\n",
    "    img_plane = np.concatenate([img_plane_x, img_plane_y, img_plane_z], 2)\n",
    "\n",
    "    depth = distance / np.linalg.norm(img_plane, 2, 2) * flt_focal\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800)\n",
      "uint16\n",
      "0\n",
      "1096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plane_depth = depth_image\n",
    "\n",
    "print(plane_depth.shape)\n",
    "print(plane_depth.dtype)\n",
    "print(plane_depth.min())\n",
    "print(plane_depth.max())\n",
    "cv2.imwrite(\"front_depth_mesh_image_cv2.png\", plane_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth image type: uint16\n",
      "Depth image shape: (800, 800)\n",
      "Reconstructed point cloud saved to reconstructed_pointcloud.ply\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi Ã¨ verificato un arresto anomalo del Kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. \n",
      "\u001b[1;31mEsaminare il codice nelle celle per identificare una possibile causa dell'errore. \n",
      "\u001b[1;31mPer altre informazioni, fare clic<a href='https://aka.ms/vscodeJupyterKernelCrash'>qui</a>. \n",
      "\u001b[1;31mPer ulteriori dettagli, visualizzare Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def reconstruct_from_depth(depth_filename, width, height, fx, fy, cx, cy, output_pointcloud_filename):\n",
    "    # Load the saved raw depth image (not normalized)\n",
    "    depth_image = o3d.io.read_image(depth_filename)\n",
    "    depth_np = np.asarray(depth_image)\n",
    "\n",
    "    # Print the data type and shape of the depth image\n",
    "    print(f\"Depth image type: {depth_np.dtype}\")\n",
    "    print(f\"Depth image shape: {depth_np.shape}\")\n",
    "\n",
    "    # Create an intrinsic matrix for the camera\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(width, height, fx, fy, cx, cy)\n",
    "\n",
    "    # Convert the depth image to a point cloud\n",
    "    pcd = o3d.geometry.PointCloud.create_from_depth_image(\n",
    "        depth_image, intrinsic, extrinsic=np.identity(4)\n",
    "    )\n",
    "\n",
    "    # Save the reconstructed point cloud to a file\n",
    "    o3d.io.write_point_cloud(output_pointcloud_filename, pcd)\n",
    "    print(f\"Reconstructed point cloud saved to {output_pointcloud_filename}\")\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# Example parameters\n",
    "depth_filename = \"front_depth_mesh_image_cv2.png\"  # The raw depth image file\n",
    "output_pointcloud_filename = \"reconstructed_pointcloud.ply\"\n",
    "\n",
    "# Intrinsic parameters (adjust based on your setup)\n",
    "width = 800  # Image width\n",
    "height = 800  # Image height\n",
    "fx = 692.82  # Focal length in x direction\n",
    "fy = 692.82  # Focal length in y direction\n",
    "cx = width / 2.0  # Principal point in x direction\n",
    "cy = height / 2.0  # Principal point in y direction\n",
    "\n",
    "# Call the reconstruction function\n",
    "reconstruct_from_depth(depth_filename, width, height, fx, fy, cx, cy, output_pointcloud_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import count_nonzero, clip, np\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/apple/ml-hypersim/blob/main/code/python/tools/scene_generate_images_tonemap.py\n",
    "def tone_map(rgb, entity_id_map):\n",
    "    assert (entity_id_map != 0).all()\n",
    "\n",
    "    gamma = 1.0 / 2.2  # standard gamma correction exponent\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    percentile = (\n",
    "        90  # we want this percentile brightness value in the unmodified image...\n",
    "    )\n",
    "    brightness_nth_percentile_desired = 0.8  # ...to be this bright after scaling\n",
    "\n",
    "    valid_mask = entity_id_map != -1\n",
    "\n",
    "    if count_nonzero(valid_mask) == 0:\n",
    "        scale = 1.0  # if there are no valid pixels, then set scale to 1.0\n",
    "    else:\n",
    "        brightness = (\n",
    "            0.3 * rgb[:, :, 0] + 0.59 * rgb[:, :, 1] + 0.11 * rgb[:, :, 2]\n",
    "        )  # \"CCIR601 YIQ\" method for computing brightness\n",
    "        brightness_valid = brightness[valid_mask]\n",
    "\n",
    "        eps = 0.0001  # if the kth percentile brightness value in the unmodified image is less than this, set the scale to 0.0 to avoid divide-by-zero\n",
    "        brightness_nth_percentile_current = np.percentile(brightness_valid, percentile)\n",
    "\n",
    "        if brightness_nth_percentile_current < eps:\n",
    "            scale = 0.0\n",
    "        else:\n",
    "            # Snavely uses the following expression in the code at https://github.com/snavely/pbrs_tonemapper/blob/master/tonemap_rgbe.py:\n",
    "            # scale = np.exp(np.log(brightness_nth_percentile_desired)*inv_gamma - np.log(brightness_nth_percentile_current))\n",
    "            #\n",
    "            # Our expression below is equivalent, but is more intuitive, because it follows more directly from the expression:\n",
    "            # (scale*brightness_nth_percentile_current)^gamma = brightness_nth_percentile_desired\n",
    "\n",
    "            scale = (\n",
    "                np.power(brightness_nth_percentile_desired, inv_gamma)\n",
    "                / brightness_nth_percentile_current\n",
    "            )\n",
    "\n",
    "    rgb_color_tm = np.power(np.maximum(scale * rgb, 0), gamma)\n",
    "    rgb_color_tm = clip(rgb_color_tm, 0, 1)\n",
    "    return rgb_color_tm\n",
    "\n",
    "\n",
    "# According to https://github.com/apple/ml-hypersim/issues/9\n",
    "def dist_2_depth(width, height, flt_focal, distance):\n",
    "    img_plane_x = (\n",
    "        np.linspace((-0.5 * width) + 0.5, (0.5 * width) - 0.5, width)\n",
    "        .reshape(1, width)\n",
    "        .repeat(height, 0)\n",
    "        .astype(np.float32)[:, :, None]\n",
    "    )\n",
    "    img_plane_y = (\n",
    "        np.linspace((-0.5 * height) + 0.5, (0.5 * height) - 0.5, height)\n",
    "        .reshape(height, 1)\n",
    "        .repeat(width, 1)\n",
    "        .astype(np.float32)[:, :, None]\n",
    "    )\n",
    "    img_plane_z = np.full([height, width, 1], flt_focal, np.float32)\n",
    "    img_plane = np.concatenate([img_plane_x, img_plane_y, img_plane_z], 2)\n",
    "\n",
    "    depth = distance / np.linalg.norm(img_plane, 2, 2) * flt_focal\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypersim preprocessing finished. Depth saved to processed_output/processed_depth.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import json  # To save the min and max depth values\n",
    "\n",
    "\n",
    "# Function to preprocess the depth image using Hypersim pipeline\n",
    "def hypersim_preprocess(depth_image_path, output_dir):\n",
    "    # Load depth image using Open3D (you can also use OpenCV)\n",
    "\n",
    "    #step 1: load the depth image\n",
    "    depth_image = o3d.io.read_image(depth_image_path)\n",
    "\n",
    "    depth_array = np.asarray(depth_image).astype(float)\n",
    "    # Save the processed depth map as PNG (scaled to millimeters)\n",
    "    plane_depth_mm = (depth_array * 1000).astype(np.uint16)\n",
    "    processed_depth_filename = os.path.join(output_dir, \"processed_depth.png\")\n",
    "    cv2.imwrite(processed_depth_filename, plane_depth_mm)\n",
    "    print(f\"Hypersim preprocessing finished. Depth saved to {processed_depth_filename}\")\n",
    "    return processed_depth_filename\n",
    "\n",
    "\n",
    "front_depth_filename = \"front_depth_image.png\"\n",
    "\n",
    "# Directory to save the processed output\n",
    "output_directory = \"processed_output\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Apply Hypersim preprocessing to the depth image\n",
    "processed_depth_filename = hypersim_preprocess(front_depth_filename, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
